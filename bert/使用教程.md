## 从bert github上面下载源代码
下载源代码和bert中文预训练模型

https://github.com/google-research/bert

https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip

## 准备数据
需要准备三个数据集train.tsv, eval.tsv, test.tsv

原始数据的处理用txt，最后再转成tsv

##### 数据格式
sentenceA\tsentenceB\tlabel

sentenceA和sentenceB至少有一个不为空，label可以是多分类也可以是二分类

##### 编写DataProcessor类
在run_classifier.py中的def main()函数中将processors的内容增加为:

  processors = {
        "cola": ColaProcessor,
        "mnli": MnliProcessor,
        "mrpc": MrpcProcessor,
        "xnli": XnliProcessor,
        "mytask": MyTaskProcessor,
    }

实现如下的MyTaskProcessor(DataProcessor)类，并将这一段代码放置在run_classifier.py和其他Processor并列的位置。具体代码请看run_classifier.py里面的class QueryTagProcessor(DataProcessor)类

## 编写运行脚本
改成自己的路径，具体请看run.sh和test.sh

## 训练&验证
sh run.sh

## 测试
sh test.sh
